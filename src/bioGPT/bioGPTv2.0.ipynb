{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Black-Box Memorization Attack with BioGPT\n",
    "\n",
    "This script simulates a black-box setting using BioGPT:\n",
    "  1. It loads BioGPT (auto-regressive) and your local PMC data (pmc_fulltext.json).\n",
    "  2. It builds a list of candidate prompts from the local data (titles and abstract snippets).\n",
    "  3. It generates many completions from BioGPT using sampling (top-k, top-p, temperature).\n",
    "  4. It computes two membership-inference metrics for each generation:\n",
    "       - A naive zlib compression ratio.\n",
    "       - The perplexity (computed using the model?s output probabilities).\n",
    "  5. It ranks the completions (here, we assume higher zlib ratio is more suspicious).\n",
    "  6. It performs a naive substring search in your local corpus to verify if any completion\n",
    "     appears verbatim.\n",
    "     \n",
    "All interactions with the model are via generate() (and a separate forward pass for scoring),\n",
    "so we're simulating a black-box interface.\n",
    "\n",
    "Authors: Nilesh Rijhwani & Bhavana Krishna\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import json\n",
    "import random\n",
    "import zlib\n",
    "from typing import List, Dict\n",
    "import re\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################################################################\n",
    "# Configuration\n",
    "###############################################################################\n",
    "MODEL_NAME = \"microsoft/BioGPT-Large\"  # or \"microsoft/BioGPT\"\n",
    "PMC_JSON_PATH = \"../Data/pubmed_2010_2024_intelligence.json\"    # local PMC data JSON file\n",
    "OUTPUT_GENERATIONS = \"biogpt_generations.json\"\n",
    "ATTACK_RESULTS = \"attack_results.json\"\n",
    "\n",
    "NUM_GENERATIONS = 4000    # Total number of completions to generate\n",
    "TOKENS_TO_GENERATE = 400  # Number of tokens to generate for each completion\n",
    "TOP_K = 50\n",
    "TOP_P = 0.95\n",
    "TEMPERATURE = 0.6\n",
    "SUBSTRING_SEARCH_MAX = 2  # Max matching articles per candidate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################################################################\n",
    "# Helper Functions\n",
    "###############################################################################\n",
    "def load_pmc_data(json_path: str) -> List[Dict]:\n",
    "    \"\"\"Load local PMC data from JSON file.\"\"\"\n",
    "    if not os.path.exists(json_path):\n",
    "        print(f\"[ERROR] File not found: {json_path}\")\n",
    "        return []\n",
    "    data=[]\n",
    "    with open(json_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if line:  # skip empty lines\n",
    "                data.append(json.loads(line))\n",
    "    return data\n",
    "\n",
    "def zlib_ratio(txt: str) -> float:\n",
    "    \"\"\"Compute a naive zlib compression ratio as a membership inference metric.\"\"\"\n",
    "    if not txt.strip():\n",
    "        return 0.0\n",
    "    compressed = zlib.compress(txt.encode(\"utf-8\"))\n",
    "    return len(txt) / len(compressed)\n",
    "\n",
    "def preprocess_text(text: str) -> str:\n",
    "    \"\"\"\n",
    "    Lowercase the text, remove punctuation, and extra whitespace.\n",
    "    \"\"\"\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)  # remove punctuation\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    return text\n",
    "\n",
    "def fuzzy_ngram_search(snippet: str, corpus: List[Dict], n: int = 2, threshold: float = 0.3, max_results: int = 2) -> List[int]:\n",
    "    \"\"\"\n",
    "    Compute n-gram overlap similarity between the snippet and the combined text\n",
    "    (title + abstract) from each article in the corpus.\n",
    "    \n",
    "    Returns indices of articles where the overlap ratio (intersection/union) \n",
    "    is at least the threshold.\n",
    "    \n",
    "    Adjust n and threshold as needed.\n",
    "    \"\"\"\n",
    "    # Preprocess snippet to remove punctuation and normalize text.\n",
    "    snippet = preprocess_text(snippet)\n",
    "    snippet_tokens = snippet.split()\n",
    "    if len(snippet_tokens) < n:\n",
    "        snippet_ngrams = set([tuple(snippet_tokens)])\n",
    "    else:\n",
    "        snippet_ngrams = set(zip(*[snippet_tokens[i:] for i in range(n)]))\n",
    "    \n",
    "    matches = []\n",
    "    for i, article in enumerate(corpus):\n",
    "        title = article.get(\"title\", {}) or \"\"\n",
    "        abstract = article.get(\"abstract\", {}) or \"\"\n",
    "        combined = preprocess_text(title + \" \" + abstract)\n",
    "        combined_tokens = combined.split()\n",
    "        if len(combined_tokens) < n:\n",
    "            combined_ngrams = set([tuple(combined_tokens)])\n",
    "        else:\n",
    "            combined_ngrams = set(zip(*[combined_tokens[i:] for i in range(n)]))\n",
    "        \n",
    "        if not snippet_ngrams or not combined_ngrams:\n",
    "            continue\n",
    "\n",
    "        intersection = snippet_ngrams.intersection(combined_ngrams)\n",
    "        union = snippet_ngrams.union(combined_ngrams)\n",
    "        similarity = len(intersection) / len(union) if union else 0.0\n",
    "\n",
    "        if similarity >= threshold:\n",
    "            matches.append(i)\n",
    "            if len(matches) >= max_results:\n",
    "                break\n",
    "\n",
    "    return matches\n",
    "\n",
    "def compute_perplexity(text: str, model, tokenizer, device: str) -> float:\n",
    "    \"\"\"\n",
    "    Compute perplexity for a given text using the model.\n",
    "    This function uses the model in a black-box way: we simply pass the text and get loss.\n",
    "    Note: In a real black-box API you might not have this ability.\n",
    "    \"\"\"\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\").to(device)\n",
    "    # Use labels identical to inputs for computing loss\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs, labels=inputs[\"input_ids\"])\n",
    "    loss = outputs.loss  # average negative log likelihood per token\n",
    "    perplexity = torch.exp(loss)\n",
    "    return perplexity.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Loading BioGPT model: microsoft/BioGPT-Large\n",
      "[INFO] Loading local PMC data from ../Data/pubmed_2010_2024_intelligence.json\n",
      "[INFO] Loaded 54583 articles from local corpus.\n"
     ]
    }
   ],
   "source": [
    "# --- Step A: Load Model & Local Data ---\n",
    "print(f\"[INFO] Loading BioGPT model: {MODEL_NAME}\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "model = AutoModelForCausalLM.from_pretrained(MODEL_NAME)\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model.to(device)\n",
    "\n",
    "print(f\"[INFO] Loading local PMC data from {PMC_JSON_PATH}\")\n",
    "corpus = load_pmc_data(PMC_JSON_PATH)\n",
    "print(f\"[INFO] Loaded {len(corpus)} articles from local corpus.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Using 106151 candidate prompts.\n"
     ]
    }
   ],
   "source": [
    "# --- Step B: Build Candidate Prompts ---\n",
    "prompts = []\n",
    "for article in corpus:\n",
    "    title = article.get(\"title\", \"\").strip()\n",
    "    if title:\n",
    "        prompts.append(title)\n",
    "    abstract = article.get(\"abstract\", \"\").strip()\n",
    "    if abstract:\n",
    "        words = abstract.split()\n",
    "        prompt_abstract = \" \".join(words[:20]) if len(words) > 20 else abstract\n",
    "        prompts.append(prompt_abstract)\n",
    "if not prompts:\n",
    "    prompts = [\"Biomedical research shows\", \"In this study, we explore\"]\n",
    "print(f\"[INFO] Using {len(prompts)} candidate prompts.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Generated 100 completions.\n",
      "[INFO] Generated 200 completions.\n",
      "[INFO] Generated 300 completions.\n",
      "[INFO] Generated 400 completions.\n",
      "[INFO] Generated 500 completions.\n",
      "[INFO] Generated 600 completions.\n",
      "[INFO] Generated 700 completions.\n",
      "[INFO] Generated 800 completions.\n",
      "[INFO] Generated 900 completions.\n",
      "[INFO] Generated 1000 completions.\n",
      "[INFO] Generated 1100 completions.\n",
      "[INFO] Generated 1200 completions.\n",
      "[INFO] Generated 1300 completions.\n",
      "[INFO] Generated 1400 completions.\n",
      "[INFO] Generated 1500 completions.\n",
      "[INFO] Generated 1600 completions.\n",
      "[INFO] Generated 1700 completions.\n",
      "[INFO] Generated 1800 completions.\n",
      "[INFO] Generated 1900 completions.\n",
      "[INFO] Generated 2000 completions.\n",
      "[INFO] Generated 2100 completions.\n",
      "[INFO] Generated 2200 completions.\n",
      "[INFO] Generated 2300 completions.\n",
      "[INFO] Generated 2400 completions.\n",
      "[INFO] Generated 2500 completions.\n",
      "[INFO] Generated 2600 completions.\n",
      "[INFO] Generated 2700 completions.\n",
      "[INFO] Generated 2800 completions.\n",
      "[INFO] Generated 2900 completions.\n",
      "[INFO] Generated 3000 completions.\n",
      "[INFO] Generated 3100 completions.\n",
      "[INFO] Generated 3200 completions.\n",
      "[INFO] Generated 3300 completions.\n",
      "[INFO] Generated 3400 completions.\n",
      "[INFO] Generated 3500 completions.\n",
      "[INFO] Generated 3600 completions.\n",
      "[INFO] Generated 3700 completions.\n",
      "[INFO] Generated 3800 completions.\n",
      "[INFO] Generated 3900 completions.\n",
      "[INFO] Generated 4000 completions.\n",
      "[INFO] Saved 4000 completions to biogpt_generations.json.\n"
     ]
    }
   ],
   "source": [
    "# --- Step C: Generate Text Completions (Black-Box) ---\n",
    "generations = []\n",
    "for i in range(NUM_GENERATIONS):\n",
    "    prompt = random.choice(prompts)\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(device)\n",
    "    with torch.no_grad():\n",
    "        output_ids = model.generate(\n",
    "            **inputs,\n",
    "            max_new_tokens=TOKENS_TO_GENERATE,\n",
    "            do_sample=True,\n",
    "            temperature=TEMPERATURE,\n",
    "            top_k=TOP_K,\n",
    "            top_p=TOP_P\n",
    "        )[0]\n",
    "    gen_text = tokenizer.decode(output_ids, skip_special_tokens=True)\n",
    "    ppl = compute_perplexity(gen_text, model, tokenizer, device)\n",
    "    generations.append({\n",
    "        \"prompt\": prompt,\n",
    "        \"generated_text\": gen_text,\n",
    "        \"perplexity\": ppl,\n",
    "        \"zlib_ratio\": zlib_ratio(gen_text)\n",
    "    })\n",
    "    if (i+1) % 100 == 0:\n",
    "        print(f\"[INFO] Generated {i+1} completions.\")\n",
    "\n",
    "with open(OUTPUT_GENERATIONS, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(generations, f, indent=2)\n",
    "print(f\"[INFO] Saved {len(generations)} completions to {OUTPUT_GENERATIONS}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Top 5 suspicious completions by zlib_ratio:\n",
      "1. zlib_ratio: 19.1169, perplexity: 5.93\n",
      "Prompt: CT ​Evaluation ​by ​Artificial ​Intelligence ​for ​Atherosclerosis, Stenosis and Vascular ​Morphology ​(CLARIFY): ​A ​Multi-center, international study.\n",
      "Generated (first 100 chars): CT Evaluation by Artificial Intelligence for Atherosclerosis, Stenosis and Vascular Morphology (CLAR...\n",
      "------------------------------------------------------------\n",
      "2. zlib_ratio: 8.4358, perplexity: 1.73\n",
      "Prompt: Access to care has always been at the heart of the concerns of the actors of psychiatry. History reminds us\n",
      "Generated (first 100 chars): Access to care has always been at the heart of the concerns of the actors of psychiatry. History rem...\n",
      "------------------------------------------------------------\n",
      "3. zlib_ratio: 7.5184, perplexity: 1.91\n",
      "Prompt: Molecular variants of vitamin B<sub>12</sub>, siderophores, and glycans occur. To take up variant forms, bacteria may express an array of\n",
      "Generated (first 100 chars): Molecular variants of vitamin B < sub > 12 < / sub >, siderophores, and glycans occur. To take up va...\n",
      "------------------------------------------------------------\n",
      "4. zlib_ratio: 7.2194, perplexity: 1.53\n",
      "Prompt: To develop a measure of alcohol affordability (AA) and compare the AA of 65 cities worldwide. In this paper, AA\n",
      "Generated (first 100 chars): To develop a measure of alcohol affordability (AA) and compare the AA of 65 cities worldwide. In thi...\n",
      "------------------------------------------------------------\n",
      "5. zlib_ratio: 7.0102, perplexity: 1.81\n",
      "Prompt: The synthesis of CdSe/CdS core/shell nanoparticles was revisited with the help of a causal inference machine learning framework. The tadpole\n",
      "Generated (first 100 chars): The synthesis of CdSe / CdS core / shell nanoparticles was revisited with the help of a causal infer...\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# --- Step D: Membership Inference Filtering ---\n",
    "# Here we combine two metrics: perplexity and zlib_ratio.\n",
    "# In this example, we simply rank by zlib_ratio (higher means more repeated structure)\n",
    "generations.sort(key=lambda x: x[\"zlib_ratio\"], reverse=True)\n",
    "top_suspicious = generations[:50]  # Top 50 candidates by zlib_ratio\n",
    "print(\"[INFO] Top 5 suspicious completions by zlib_ratio:\")\n",
    "for j, cand in enumerate(top_suspicious[:5], start=1):\n",
    "    print(f\"{j}. zlib_ratio: {cand['zlib_ratio']:.4f}, perplexity: {cand['perplexity']:.2f}\")\n",
    "    print(f\"Prompt: {cand['prompt']}\")\n",
    "    print(f\"Generated (first 100 chars): {cand['generated_text'][:100]}...\")\n",
    "    print(\"-\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'prompt': 'Access to care has always been at the heart of the concerns of the actors of psychiatry. History reminds us',\n",
       " 'generated_text': 'Access to care has always been at the heart of the concerns of the actors of psychiatry. History reminds us that access to care is a political, social and cultural issue. Access to care is a concept that is not new, but it has been increasingly used in the last 2 0 years. In this context, access to care is a question that has been raised in the context of deinstitutionalisation and of the growth of the community mental health teams. In this context, access to care is a question that has been raised in the context of deinstitutionalisation and of the growth of the community mental health teams. Access to care is a question that has been raised in the context of deinstitutionalisation and of the growth of the community mental health teams. Access to care is a question that has been raised in the context of deinstitutionalisation and of the growth of the community mental health teams. Access to care is a question that has been raised in the context of deinstitutionalisation and of the growth of the community mental health teams. Access to care is a question that has been raised in the context of deinstitutionalisation and of the growth of the community mental health teams. Access to care is a question that has been raised in the context of deinstitutionalisation and of the growth of the community mental health teams. Access to care is a question that has been raised in the context of deinstitutionalisation and of the growth of the community mental health teams. Access to care is a question that has been raised in the context of deinstitutionalisation and of the growth of the community mental health teams. Access to care is a question that has been raised in the context of deinstitutionalisation and of the growth of the community mental health teams. Access to care is a question that has been raised in the context of deinstitutionalisation and of the growth of the community mental health teams. Access to care is a question that has been raised in the context of deinstitutionalisation and of the growth of the community mental health teams. Access to care is a question that has been raised in the context of deinstitutionalisation and of',\n",
       " 'perplexity': 1.7323567867279053,\n",
       " 'zlib_ratio': 8.43579766536965}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_suspicious[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Verified memorized samples (exact substring matches): 0\n"
     ]
    }
   ],
   "source": [
    "# --- Step E: Verification via Substring Search ---\n",
    "verified_memorized = []\n",
    "for suspicious in top_suspicious:\n",
    "    snippet = suspicious[\"generated_text\"]\n",
    "    # Use fuzzy matching (with trigrams and threshold of 0.5, adjust as needed)\n",
    "    matches = fuzzy_ngram_search(snippet, corpus, n=2, threshold=0.3, max_results=SUBSTRING_SEARCH_MAX)\n",
    "    if matches:\n",
    "        suspicious[\"matches\"] = matches\n",
    "        verified_memorized.append(suspicious)\n",
    "\n",
    "print(f\"[INFO] Verified memorized samples (exact substring matches): {len(verified_memorized)}\")\n",
    "for v in verified_memorized:\n",
    "    print(\"=\" * 60)\n",
    "    print(f\"zlib_ratio: {v['zlib_ratio']:.4f}, perplexity: {v['perplexity']:.2f}\")\n",
    "    print(f\"Prompt: {v['prompt']}\")\n",
    "    print(f\"Generated Text: {v['generated_text']}\")\n",
    "    print(f\"Found in corpus indices: {v['matches']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Attack results saved to attack_results.json\n"
     ]
    }
   ],
   "source": [
    "# --- Save Final Attack Results ---\n",
    "results = {\n",
    "    \"generations\": generations,\n",
    "    \"verified_memorized\": verified_memorized\n",
    "}\n",
    "with open(ATTACK_RESULTS, \"w\", encoding=\"utf-8\") as rf:\n",
    "    json.dump(results, rf, indent=2)\n",
    "print(f\"[INFO] Attack results saved to {ATTACK_RESULTS}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dataCon",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11 (main, Dec 11 2024, 16:28:39) [GCC 11.2.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "97ec761001ea25a843739c998b516e9c906daf472aa6d0129e56e3aea5e0f0e3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

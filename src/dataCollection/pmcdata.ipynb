{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import json\n",
    "from datetime import datetime, timedelta\n",
    "from Bio import Entrez\n",
    "\n",
    "Entrez.email = \"<email_adress_removed>\"  # Required by NCBI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def month_year_iter(start_year, start_month, end_year, end_month):\n",
    "    \"\"\"\n",
    "    Generate (year, month) pairs from (start_year, start_month) up to (end_year, end_month).\n",
    "    \"\"\"\n",
    "    ym_start = 12 * start_year + start_month - 1\n",
    "    ym_end = 12 * end_year + end_month - 1\n",
    "    for ym in range(ym_start, ym_end + 1):\n",
    "        y, m = divmod(ym, 12)\n",
    "        yield y, m + 1\n",
    "\n",
    "def esearch_month(year, month, extra_query):\n",
    "    \"\"\"\n",
    "    Perform an ESearch for all articles published in a given month of a given year,\n",
    "    also matching extra_query. Returns the list of PMIDs (as strings).\n",
    "    \"\"\"\n",
    "    # Build the range for this specific month: [YYYY/MM/01 - YYYY/MM/LastDay]\n",
    "    start_date = datetime(year, month, 1)\n",
    "    if month == 12:\n",
    "        end_date = datetime(year + 1, 1, 1) - timedelta(days=1)\n",
    "    else:\n",
    "        end_date = datetime(year, month + 1, 1) - timedelta(days=1)\n",
    "\n",
    "    # Create the date filter part\n",
    "    date_part = f'(\"{start_date.strftime(\"%Y/%m/%d\")}\"[PDAT] : \"{end_date.strftime(\"%Y/%m/%d\")}\"[PDAT])'\n",
    "    \n",
    "    # Combine the date filter with the extra search query, e.g. intelligence[TIAB]\n",
    "    # NOTE: you could also do intelligence[All Fields], or use parentheses for more complex Boolean logic.\n",
    "    query = f\"({date_part}) AND ({extra_query})\"\n",
    "\n",
    "    print(f\"Searching PubMed for {query}...\")\n",
    "\n",
    "    # ESearch\n",
    "    search_handle = Entrez.esearch(\n",
    "        db=\"pubmed\",\n",
    "        term=query,\n",
    "        retmax=9999,      # ESearch can only fetch up to 9999\n",
    "        usehistory=\"y\"    # Use history for chunked retrieval\n",
    "    )\n",
    "    search_results = Entrez.read(search_handle)\n",
    "    search_handle.close()\n",
    "\n",
    "    webenv = search_results[\"WebEnv\"]\n",
    "    query_key = search_results[\"QueryKey\"]\n",
    "    count = int(search_results[\"Count\"])\n",
    "    print(f\" Found {count} articles for {year}-{month:02d} matching query: {extra_query}\")\n",
    "\n",
    "    # Retrieve PMIDs in increments (up to 9999)\n",
    "    pmid_list = []\n",
    "    batch_size = 1000\n",
    "    for start in range(0, min(count, 9999), batch_size):\n",
    "        fetch_handle = Entrez.esearch(\n",
    "            db=\"pubmed\",\n",
    "            webenv=webenv,\n",
    "            query_key=query_key,\n",
    "            term=query,\n",
    "            retstart=start,\n",
    "            retmax=batch_size\n",
    "        )\n",
    "        data = Entrez.read(fetch_handle)\n",
    "        fetch_handle.close()\n",
    "        pmid_list.extend(data[\"IdList\"])\n",
    "        time.sleep(0.3)  # courtesy delay\n",
    "\n",
    "    return pmid_list\n",
    "\n",
    "def fetch_pubmed_metadata(pmid_list):\n",
    "    \"\"\"\n",
    "    Given a list of PMIDs, use EFetch to retrieve PubMed metadata in smaller batches.\n",
    "    Returns a list of dicts with {pmid, title, abstract, etc.}\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    batch_size = 500\n",
    "    for i in range(0, len(pmid_list), batch_size):\n",
    "        batch_pmids = pmid_list[i : i+batch_size]\n",
    "        id_string = \",\".join(batch_pmids)\n",
    "\n",
    "        handle = Entrez.efetch(db=\"pubmed\", id=id_string, retmode=\"xml\")\n",
    "        records = Entrez.read(handle)\n",
    "        handle.close()\n",
    "\n",
    "        for record in records.get(\"PubmedArticle\", []):\n",
    "            pmid = record[\"MedlineCitation\"][\"PMID\"]\n",
    "            article = record[\"MedlineCitation\"].get(\"Article\", {})\n",
    "            title = article.get(\"ArticleTitle\", \"\")\n",
    "            abstract_text = \"\"\n",
    "            if \"Abstract\" in article and \"AbstractText\" in article[\"Abstract\"]:\n",
    "                abs_parts = article[\"Abstract\"][\"AbstractText\"]\n",
    "                if isinstance(abs_parts, list):\n",
    "                    abstract_text = \" \".join(str(part) for part in abs_parts)\n",
    "                else:\n",
    "                    abstract_text = str(abs_parts)\n",
    "            \n",
    "            results.append({\n",
    "                \"pmid\": pmid,\n",
    "                \"title\": title,\n",
    "                \"abstract\": abstract_text\n",
    "            })\n",
    "\n",
    "        time.sleep(0.3)  # courtesy delay\n",
    "    return results\n",
    "\n",
    "\n",
    "def fetch_pmc_id(pmid):\n",
    "    \"\"\"\n",
    "    Check if a PubMed article is in PMC (returns 'PMC########' if yes, else None).\n",
    "    \"\"\"\n",
    "    try:\n",
    "        link_handle = Entrez.elink(dbfrom=\"pubmed\", id=pmid, linkname=\"pubmed_pmc\")\n",
    "        link_result = Entrez.read(link_handle)\n",
    "        link_handle.close()\n",
    "    except Exception as e:\n",
    "        print(f\"Error retrieving PMC link for PMID {pmid}: {e}\")\n",
    "        return None\n",
    "\n",
    "    pmcid = None\n",
    "    for linkset in link_result:\n",
    "        if \"LinkSetDb\" in linkset:\n",
    "            for linksetdb in linkset[\"LinkSetDb\"]:\n",
    "                if linksetdb[\"LinkName\"] == \"pubmed_pmc\":\n",
    "                    for link in linksetdb[\"Link\"]:\n",
    "                        pmcid_num = link[\"Id\"]\n",
    "                        pmcid = f\"PMC{pmcid_num}\"\n",
    "                        break\n",
    "    return pmcid\n",
    "\n",
    "def fetch_pmc_full_text(pmcid):\n",
    "    \"\"\"\n",
    "    Fetch full text from PMC (if open access).\n",
    "    Returns a string with the text, or None if unavailable.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        handle = Entrez.efetch(db=\"pmc\", id=pmcid, retmode=\"xml\", rettype=\"full\")\n",
    "        xml_data = handle.read().decode(\"utf-8\")\n",
    "        handle.close()\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching from PMC ID {pmcid}: {e}\")\n",
    "        return None\n",
    "\n",
    "    # A naive example that extracts lines between <body>...</body>\n",
    "    in_body_section = False\n",
    "    full_text_lines = []\n",
    "    for line in xml_data.splitlines():\n",
    "        if \"<body\" in line:\n",
    "            in_body_section = True\n",
    "        elif \"</body>\" in line:\n",
    "            in_body_section = False\n",
    "            full_text_lines.append(line)\n",
    "        if in_body_section:\n",
    "            full_text_lines.append(line)\n",
    "\n",
    "    return \"\\n\".join(full_text_lines) if full_text_lines else None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "extra_query = \"intelligence[TIAB]\"  # or \"intelligence[All Fields]\", etc.\n",
    "\n",
    "all_records = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searching PubMed for ((\"2010/01/01\"[PDAT] : \"2010/01/31\"[PDAT])) AND (intelligence[TIAB])...\n",
      " Found 222 articles for 2010-01 matching query: intelligence[TIAB]\n",
      "Found <built-in method count of list object at 0x10dc171c0> articles in PubMed for query intelligence[TIAB] in 2010-01\n",
      "Searching PubMed for ((\"2010/01/01\"[PDAT] : \"2010/01/31\"[PDAT])) AND (intelligence[TIAB])...\n",
      " Found 222 articles for 2010-01 matching query: intelligence[TIAB]\n",
      " > Accumulated total records so far: 222\n",
      "Searching PubMed for ((\"2010/02/01\"[PDAT] : \"2010/02/28\"[PDAT])) AND (intelligence[TIAB])...\n",
      " Found 95 articles for 2010-02 matching query: intelligence[TIAB]\n",
      " > Accumulated total records so far: 317\n",
      "Searching PubMed for ((\"2010/03/01\"[PDAT] : \"2010/03/31\"[PDAT])) AND (intelligence[TIAB])...\n",
      " Found 141 articles for 2010-03 matching query: intelligence[TIAB]\n",
      " > Accumulated total records so far: 458\n",
      "Searching PubMed for ((\"2010/04/01\"[PDAT] : \"2010/04/30\"[PDAT])) AND (intelligence[TIAB])...\n",
      " Found 101 articles for 2010-04 matching query: intelligence[TIAB]\n",
      " > Accumulated total records so far: 559\n",
      "Searching PubMed for ((\"2010/05/01\"[PDAT] : \"2010/05/31\"[PDAT])) AND (intelligence[TIAB])...\n",
      " Found 99 articles for 2010-05 matching query: intelligence[TIAB]\n",
      " > Accumulated total records so far: 658\n",
      "Searching PubMed for ((\"2010/06/01\"[PDAT] : \"2010/06/30\"[PDAT])) AND (intelligence[TIAB])...\n",
      " Found 116 articles for 2010-06 matching query: intelligence[TIAB]\n",
      " > Accumulated total records so far: 774\n",
      "Searching PubMed for ((\"2010/07/01\"[PDAT] : \"2010/07/31\"[PDAT])) AND (intelligence[TIAB])...\n",
      " Found 115 articles for 2010-07 matching query: intelligence[TIAB]\n",
      " > Accumulated total records so far: 889\n",
      "Searching PubMed for ((\"2010/08/01\"[PDAT] : \"2010/08/31\"[PDAT])) AND (intelligence[TIAB])...\n",
      " Found 83 articles for 2010-08 matching query: intelligence[TIAB]\n",
      " > Accumulated total records so far: 972\n",
      "Searching PubMed for ((\"2010/09/01\"[PDAT] : \"2010/09/30\"[PDAT])) AND (intelligence[TIAB])...\n",
      " Found 109 articles for 2010-09 matching query: intelligence[TIAB]\n",
      " > Accumulated total records so far: 1081\n",
      "Searching PubMed for ((\"2010/10/01\"[PDAT] : \"2010/10/31\"[PDAT])) AND (intelligence[TIAB])...\n",
      " Found 125 articles for 2010-10 matching query: intelligence[TIAB]\n",
      " > Accumulated total records so far: 1206\n",
      "Searching PubMed for ((\"2010/11/01\"[PDAT] : \"2010/11/30\"[PDAT])) AND (intelligence[TIAB])...\n",
      " Found 93 articles for 2010-11 matching query: intelligence[TIAB]\n",
      " > Accumulated total records so far: 1299\n",
      "Searching PubMed for ((\"2010/12/01\"[PDAT] : \"2010/12/31\"[PDAT])) AND (intelligence[TIAB])...\n",
      " Found 119 articles for 2010-12 matching query: intelligence[TIAB]\n",
      " > Accumulated total records so far: 1418\n",
      "Searching PubMed for ((\"2011/01/01\"[PDAT] : \"2011/01/31\"[PDAT])) AND (intelligence[TIAB])...\n",
      " Found 227 articles for 2011-01 matching query: intelligence[TIAB]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 19\u001b[0m\n\u001b[1;32m     17\u001b[0m rec[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpmc_id\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m fetch_pmc_id(rec[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpmid\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m rec[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpmc_id\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[0;32m---> 19\u001b[0m     rec[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfull_text\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m fetch_pmc_full_text(rec[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpmc_id\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     21\u001b[0m     rec[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfull_text\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[20], line 133\u001b[0m, in \u001b[0;36mfetch_pmc_full_text\u001b[0;34m(pmcid)\u001b[0m\n\u001b[1;32m    131\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    132\u001b[0m     handle \u001b[38;5;241m=\u001b[39m Entrez\u001b[38;5;241m.\u001b[39mefetch(db\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpmc\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mid\u001b[39m\u001b[38;5;241m=\u001b[39mpmcid, retmode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxml\u001b[39m\u001b[38;5;124m\"\u001b[39m, rettype\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfull\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 133\u001b[0m     xml_data \u001b[38;5;241m=\u001b[39m handle\u001b[38;5;241m.\u001b[39mread()\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    134\u001b[0m     handle\u001b[38;5;241m.\u001b[39mclose()\n\u001b[1;32m    135\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m/opt/anaconda3/envs/dataCon/lib/python3.11/http/client.py:467\u001b[0m, in \u001b[0;36mHTTPResponse.read\u001b[0;34m(self, amt)\u001b[0m\n\u001b[1;32m    464\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    466\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchunked:\n\u001b[0;32m--> 467\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_read_chunked(amt)\n\u001b[1;32m    469\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m amt \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    470\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlength \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m amt \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlength:\n\u001b[1;32m    471\u001b[0m         \u001b[38;5;66;03m# clip the read to the \"end of response\"\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/dataCon/lib/python3.11/http/client.py:590\u001b[0m, in \u001b[0;36mHTTPResponse._read_chunked\u001b[0;34m(self, amt)\u001b[0m\n\u001b[1;32m    588\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    589\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 590\u001b[0m         chunk_left \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_chunk_left()\n\u001b[1;32m    591\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m chunk_left \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    592\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/dataCon/lib/python3.11/http/client.py:573\u001b[0m, in \u001b[0;36mHTTPResponse._get_chunk_left\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    571\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_safe_read(\u001b[38;5;241m2\u001b[39m)  \u001b[38;5;66;03m# toss the CRLF at the end of the chunk\u001b[39;00m\n\u001b[1;32m    572\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 573\u001b[0m     chunk_left \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_read_next_chunk_size()\n\u001b[1;32m    574\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m:\n\u001b[1;32m    575\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m IncompleteRead(\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/dataCon/lib/python3.11/http/client.py:533\u001b[0m, in \u001b[0;36mHTTPResponse._read_next_chunk_size\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    531\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_read_next_chunk_size\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    532\u001b[0m     \u001b[38;5;66;03m# Read the next chunk size from the file\u001b[39;00m\n\u001b[0;32m--> 533\u001b[0m     line \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfp\u001b[38;5;241m.\u001b[39mreadline(_MAXLINE \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    534\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(line) \u001b[38;5;241m>\u001b[39m _MAXLINE:\n\u001b[1;32m    535\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m LineTooLong(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mchunk size\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/dataCon/lib/python3.11/socket.py:718\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    716\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m    717\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 718\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sock\u001b[38;5;241m.\u001b[39mrecv_into(b)\n\u001b[1;32m    719\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[1;32m    720\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/dataCon/lib/python3.11/ssl.py:1314\u001b[0m, in \u001b[0;36mSSLSocket.recv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1310\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m flags \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   1311\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1312\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[1;32m   1313\u001b[0m           \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)\n\u001b[0;32m-> 1314\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mread(nbytes, buffer)\n\u001b[1;32m   1315\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1316\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mrecv_into(buffer, nbytes, flags)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/dataCon/lib/python3.11/ssl.py:1166\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1164\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1165\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1166\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m, buffer)\n\u001b[1;32m   1167\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1168\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for (year, month) in month_year_iter(2010, 1, 2024, 12):\n",
    "    pmids_for_month = esearch_month(year, month, extra_query=extra_query)\n",
    "    print(f\"Found {pmids_for_month.count} articles in PubMed for query {extra_query} in {year}-{month:02d}\")\n",
    "    if not pmids_for_month:\n",
    "        continue\n",
    "    all_records=[]\n",
    "\n",
    "    for (year, month) in month_year_iter(2010, 1, 2024, 12):\n",
    "        pmids_for_month = esearch_month(year, month, extra_query=extra_query)\n",
    "        if not pmids_for_month:\n",
    "            continue\n",
    "        \n",
    "        monthly_records = fetch_pubmed_metadata(pmids_for_month)\n",
    "\n",
    "        # If you want, do the PMC / full-text retrieval here ...\n",
    "        for rec in monthly_records:\n",
    "            rec[\"pmc_id\"] = fetch_pmc_id(rec[\"pmid\"])\n",
    "            if rec[\"pmc_id\"]:\n",
    "                rec[\"full_text\"] = fetch_pmc_full_text(rec[\"pmc_id\"])\n",
    "            else:\n",
    "                rec[\"full_text\"] = None\n",
    "            time.sleep(0.3)\n",
    "\n",
    "        all_records.extend(monthly_records)\n",
    "        print(f\" > Accumulated total records so far: {len(all_records)}\")\n",
    "\n",
    "        # Save partial results every month\n",
    "        with open(\"pubmed_2010_2024_intelligence.json\", \"a\", encoding=\"utf-8\") as f:\n",
    "            for r in monthly_records:\n",
    "                f.write(json.dumps(r, ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "    print(\"All done!\")\n",
    "    print(f\"Total articles in final data: {len(all_records)}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10 (default, Mar 18 2025, 20:04:55) \n[GCC 9.4.0]"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
